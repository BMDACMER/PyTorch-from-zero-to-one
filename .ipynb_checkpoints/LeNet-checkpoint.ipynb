{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：https://github.com/L1aoXingyu/lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epoches = 50\n",
    "\n",
    "# 数据增强\n",
    "data_tf = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize([0.5],[0.5])])\n",
    "\n",
    "# 加载数据\n",
    "train_dataset = MNIST('data/', train=True, transform=data_tf)\n",
    "test_dataset = MNIST('data/', train=False, transform=data_tf)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 搭建网络\n",
    "class Lenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lenet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 3, stride=1, padding=1),    # 输入为 32*32\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' 前向传播函数'''\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x.view(x.size(0), -1))   # 拉平 后 在传入全连接层\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50] Loss: 0.03536, Acc: 22.43, Time: 28.1 s\n",
      "[2/50] Loss: 0.03154, Acc: 50.83, Time: 27.3 s\n",
      "[3/50] Loss: 0.01761, Acc: 72.75, Time: 28.1 s\n",
      "[4/50] Loss: 0.00894, Acc: 84.22, Time: 28.2 s\n",
      "[5/50] Loss: 0.00680, Acc: 87.52, Time: 27.8 s\n",
      "[6/50] Loss: 0.00582, Acc: 89.10, Time: 28.3 s\n",
      "[7/50] Loss: 0.00523, Acc: 90.11, Time: 28.3 s\n",
      "[8/50] Loss: 0.00480, Acc: 90.85, Time: 28.3 s\n",
      "[9/50] Loss: 0.00447, Acc: 91.49, Time: 28.1 s\n",
      "[10/50] Loss: 0.00418, Acc: 92.00, Time: 28.6 s\n",
      "[11/50] Loss: 0.00393, Acc: 92.50, Time: 28.7 s\n",
      "[12/50] Loss: 0.00370, Acc: 92.98, Time: 28.6 s\n",
      "[13/50] Loss: 0.00349, Acc: 93.37, Time: 28.2 s\n",
      "[14/50] Loss: 0.00330, Acc: 93.73, Time: 28.0 s\n",
      "[15/50] Loss: 0.00313, Acc: 94.04, Time: 29.2 s\n",
      "[16/50] Loss: 0.00297, Acc: 94.29, Time: 29.3 s\n",
      "[17/50] Loss: 0.00282, Acc: 94.58, Time: 28.8 s\n",
      "[18/50] Loss: 0.00269, Acc: 94.84, Time: 28.5 s\n",
      "[19/50] Loss: 0.00256, Acc: 95.14, Time: 28.5 s\n",
      "[20/50] Loss: 0.00245, Acc: 95.30, Time: 28.8 s\n",
      "[21/50] Loss: 0.00235, Acc: 95.52, Time: 28.7 s\n",
      "[22/50] Loss: 0.00226, Acc: 95.71, Time: 28.6 s\n",
      "[23/50] Loss: 0.00217, Acc: 95.86, Time: 28.2 s\n",
      "[24/50] Loss: 0.00210, Acc: 96.01, Time: 28.5 s\n",
      "[25/50] Loss: 0.00203, Acc: 96.14, Time: 28.7 s\n",
      "[26/50] Loss: 0.00196, Acc: 96.25, Time: 28.2 s\n",
      "[27/50] Loss: 0.00190, Acc: 96.37, Time: 28.9 s\n",
      "[28/50] Loss: 0.00185, Acc: 96.49, Time: 28.7 s\n",
      "[29/50] Loss: 0.00180, Acc: 96.56, Time: 28.8 s\n",
      "[30/50] Loss: 0.00175, Acc: 96.66, Time: 29.0 s\n",
      "[31/50] Loss: 0.00171, Acc: 96.71, Time: 28.4 s\n",
      "[32/50] Loss: 0.00167, Acc: 96.80, Time: 28.3 s\n",
      "[33/50] Loss: 0.00163, Acc: 96.89, Time: 27.6 s\n",
      "[34/50] Loss: 0.00159, Acc: 96.91, Time: 28.1 s\n",
      "[35/50] Loss: 0.00156, Acc: 97.01, Time: 28.0 s\n",
      "[36/50] Loss: 0.00153, Acc: 97.03, Time: 28.2 s\n",
      "[37/50] Loss: 0.00149, Acc: 97.07, Time: 28.0 s\n",
      "[38/50] Loss: 0.00147, Acc: 97.17, Time: 28.2 s\n",
      "[39/50] Loss: 0.00144, Acc: 97.19, Time: 29.5 s\n",
      "[40/50] Loss: 0.00141, Acc: 97.22, Time: 28.5 s\n",
      "[41/50] Loss: 0.00139, Acc: 97.30, Time: 28.1 s\n",
      "[42/50] Loss: 0.00137, Acc: 97.32, Time: 28.4 s\n",
      "[43/50] Loss: 0.00135, Acc: 97.41, Time: 28.5 s\n",
      "[44/50] Loss: 0.00132, Acc: 97.44, Time: 28.3 s\n",
      "[45/50] Loss: 0.00131, Acc: 97.48, Time: 28.4 s\n",
      "[46/50] Loss: 0.00128, Acc: 97.51, Time: 28.8 s\n",
      "[47/50] Loss: 0.00126, Acc: 97.52, Time: 28.8 s\n",
      "[48/50] Loss: 0.00125, Acc: 97.60, Time: 29.1 s\n",
      "[49/50] Loss: 0.00123, Acc: 97.62, Time: 29.2 s\n",
      "[50/50] Loss: 0.00122, Acc: 97.67, Time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "lenet = Lenet()\n",
    "\n",
    "# 定义评价函数 和 优化函数\n",
    "criterian = nn.CrossEntropyLoss(reduction='mean')   # size_average=False\n",
    "optimizer = optim.SGD(lenet.parameters(), lr=learning_rate)\n",
    "\n",
    "# train\n",
    "for i in range(epoches):\n",
    "    since = time.time()\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    for (img, label) in train_loader:\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = lenet(img)\n",
    "        loss = criterian(output, label)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predict = torch.max(output, 1)\n",
    "        correct_num = (predict == label).sum()\n",
    "        running_acc += correct_num.item()\n",
    "    \n",
    "    running_loss /= len(train_dataset)\n",
    "    running_acc /= len(train_dataset)\n",
    "    print(\"[%d/%d] Loss: %.5f, Acc: %.2f, Time: %.1f s\" %(i+1, epoches, running_loss, 100*running_acc, time.time()-since))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:Loss:0.00108, Acc:98.09 %\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "lenet.eval()\n",
    "\n",
    "testloss = 0.\n",
    "testacc = 0.\n",
    "for (img, label) in test_loader:\n",
    "    img = Variable(img)\n",
    "    label = Variable(label)\n",
    "    \n",
    "    output = lenet(img)\n",
    "    loss = criterian(output, label)\n",
    "    \n",
    "    testloss += loss.item()\n",
    "    _, pred = output.max(1)\n",
    "    num_correct = (pred == label).sum().item()\n",
    "    testacc += num_correct\n",
    "\n",
    "testloss /= len(test_dataset)\n",
    "testacc /= len(test_dataset)\n",
    "print(\"Test:Loss:%.5f, Acc:%.2f %%\" %(testloss, 100*testacc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改进的LeNet--- 添加了激活函数 \n",
    "\n",
    "\n",
    "时间增加了 但是精度几乎没怎么提高（仅仅提高了0.02个百分点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        #定义卷积层，1个输入通道，6个输出通道，5*5的卷积filter，外层补上了两圈0,因为输入的是32*32\n",
    "        self.conv_1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.conv_2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc_1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc_2 = nn.Linear(120, 84)\n",
    "        self.fc_3 = nn.Linear(84, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv_1(x)) \n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x))\n",
    "        x = self.fc_3(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50] Loss: 0.03597, Acc: 9.91, Time: 31.4 s\n",
      "[2/50] Loss: 0.03586, Acc: 10.08, Time: 31.7 s\n",
      "[3/50] Loss: 0.03570, Acc: 11.33, Time: 32.5 s\n",
      "[4/50] Loss: 0.03546, Acc: 19.61, Time: 32.8 s\n",
      "[5/50] Loss: 0.03496, Acc: 40.74, Time: 33.5 s\n",
      "[6/50] Loss: 0.03360, Acc: 53.13, Time: 36.2 s\n",
      "[7/50] Loss: 0.02832, Acc: 57.84, Time: 32.5 s\n",
      "[8/50] Loss: 0.01700, Acc: 73.20, Time: 32.0 s\n",
      "[9/50] Loss: 0.00967, Acc: 83.28, Time: 32.3 s\n",
      "[10/50] Loss: 0.00699, Acc: 87.13, Time: 32.5 s\n",
      "[11/50] Loss: 0.00574, Acc: 89.28, Time: 32.5 s\n",
      "[12/50] Loss: 0.00497, Acc: 90.64, Time: 31.9 s\n",
      "[13/50] Loss: 0.00440, Acc: 91.69, Time: 31.9 s\n",
      "[14/50] Loss: 0.00397, Acc: 92.49, Time: 31.9 s\n",
      "[15/50] Loss: 0.00361, Acc: 93.20, Time: 32.6 s\n",
      "[16/50] Loss: 0.00331, Acc: 93.69, Time: 32.9 s\n",
      "[17/50] Loss: 0.00307, Acc: 94.23, Time: 32.9 s\n",
      "[18/50] Loss: 0.00287, Acc: 94.63, Time: 32.5 s\n",
      "[19/50] Loss: 0.00270, Acc: 94.86, Time: 32.6 s\n",
      "[20/50] Loss: 0.00256, Acc: 95.15, Time: 32.7 s\n",
      "[21/50] Loss: 0.00243, Acc: 95.34, Time: 33.0 s\n",
      "[22/50] Loss: 0.00232, Acc: 95.59, Time: 32.4 s\n",
      "[23/50] Loss: 0.00222, Acc: 95.81, Time: 32.3 s\n",
      "[24/50] Loss: 0.00214, Acc: 95.89, Time: 32.3 s\n",
      "[25/50] Loss: 0.00206, Acc: 96.03, Time: 32.9 s\n",
      "[26/50] Loss: 0.00199, Acc: 96.17, Time: 32.2 s\n",
      "[27/50] Loss: 0.00192, Acc: 96.32, Time: 32.4 s\n",
      "[28/50] Loss: 0.00186, Acc: 96.39, Time: 32.1 s\n",
      "[29/50] Loss: 0.00180, Acc: 96.49, Time: 32.3 s\n",
      "[30/50] Loss: 0.00175, Acc: 96.61, Time: 32.4 s\n",
      "[31/50] Loss: 0.00170, Acc: 96.69, Time: 32.4 s\n",
      "[32/50] Loss: 0.00166, Acc: 96.78, Time: 32.4 s\n",
      "[33/50] Loss: 0.00162, Acc: 96.81, Time: 32.2 s\n",
      "[34/50] Loss: 0.00158, Acc: 96.91, Time: 32.5 s\n",
      "[35/50] Loss: 0.00155, Acc: 96.97, Time: 32.4 s\n",
      "[36/50] Loss: 0.00151, Acc: 97.05, Time: 33.1 s\n",
      "[37/50] Loss: 0.00148, Acc: 97.08, Time: 34.1 s\n",
      "[38/50] Loss: 0.00145, Acc: 97.17, Time: 33.5 s\n",
      "[39/50] Loss: 0.00143, Acc: 97.23, Time: 33.3 s\n",
      "[40/50] Loss: 0.00139, Acc: 97.27, Time: 32.9 s\n",
      "[41/50] Loss: 0.00138, Acc: 97.30, Time: 33.7 s\n",
      "[42/50] Loss: 0.00135, Acc: 97.38, Time: 33.3 s\n",
      "[43/50] Loss: 0.00132, Acc: 97.40, Time: 32.4 s\n",
      "[44/50] Loss: 0.00130, Acc: 97.45, Time: 32.5 s\n",
      "[45/50] Loss: 0.00128, Acc: 97.50, Time: 32.3 s\n",
      "[46/50] Loss: 0.00126, Acc: 97.47, Time: 32.6 s\n",
      "[47/50] Loss: 0.00124, Acc: 97.57, Time: 32.4 s\n",
      "[48/50] Loss: 0.00122, Acc: 97.60, Time: 32.3 s\n",
      "[49/50] Loss: 0.00120, Acc: 97.64, Time: 32.6 s\n",
      "[50/50] Loss: 0.00118, Acc: 97.69, Time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "model\n",
    "\n",
    "criterian = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# train\n",
    "for i in range(epoches):\n",
    "    start = time.time()\n",
    "    running_loss=0.\n",
    "    running_acc = 0.\n",
    "    for (img, label) in train_loader:\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(img)  # 前向传播\n",
    "        loss = criterian(out, label)\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, pred = out.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        running_acc += num_correct\n",
    "    \n",
    "    running_loss /= len(train_dataset)\n",
    "    running_acc /= len(train_dataset)\n",
    "    print(\"[%d/%d] Loss: %.5f, Acc: %.2f, Time: %.1f s\" %(i+1, epoches, running_loss, 100*running_acc, time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:Loss:0.00108, Acc:98.09 %\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "lenet.eval()\n",
    "\n",
    "testloss = 0.\n",
    "testacc = 0.\n",
    "for (img, label) in test_loader:\n",
    "    img = Variable(img)\n",
    "    label = Variable(label)\n",
    "    \n",
    "    output = lenet(img)\n",
    "    loss = criterian(output, label)\n",
    "    \n",
    "    testloss += loss.item()\n",
    "    _, pred = output.max(1)\n",
    "    num_correct = (pred == label).sum().item()\n",
    "    testacc += num_correct\n",
    "\n",
    "testloss /= len(test_dataset)\n",
    "testacc /= len(test_dataset)\n",
    "print(\"Test:Loss:%.5f, Acc:%.2f %%\" %(testloss, 100*testacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
