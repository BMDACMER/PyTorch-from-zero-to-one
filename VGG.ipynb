{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 在MNIST 数据集上测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络结构\n",
    "\n",
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M',\n",
    "          512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512,\n",
    "          512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512,\n",
    "          512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    \n",
    "    def __init__(self, features, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "    \n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 1   # MNIST为灰度图像    通道数为1   若为彩色图像 通道数为 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def vgg11(**kwargs):\n",
    "    return VGG(make_layers(cfg['A'], batch_norm=True), **kwargs)\n",
    "\n",
    "\n",
    "def vgg13(**kwargs):\n",
    "    return VGG(make_layers(cfg['B'], batch_norm=True), **kwargs)\n",
    "\n",
    "\n",
    "def vgg16(**kwargs):\n",
    "    return VGG(make_layers(cfg['D'], batch_norm=True), **kwargs)\n",
    "\n",
    "\n",
    "def vgg19(**kwargs):\n",
    "    return VGG(make_layers(cfg['E'], batch_norm=True), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "batch_size = 100\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "\n",
    "# 数据增强\n",
    "transform = transforms.Compose(\n",
    "[\n",
    "    transforms.RandomHorizontalFlip(),   # 对图片进行概率为0.5 随机翻转\n",
    "    transforms.RandomGrayscale(),         # 随机调整图片的亮度\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 加载数据\n",
    "trainset = torchvision.datasets.MNIST(root='data/', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testset = torchvision.datasets.MNIST(root='data/', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "vgg_model = vgg11()   # num_classes 默认为 10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training!\n",
      "[1/20] Loss: 0.00469, Acc: 87.98, Time: 44.5 s\n",
      "[2/20] Loss: 0.00111, Acc: 96.84, Time: 33.1 s\n",
      "[3/20] Loss: 0.00071, Acc: 98.02, Time: 33.3 s\n",
      "[4/20] Loss: 0.00050, Acc: 98.64, Time: 33.6 s\n",
      "[5/20] Loss: 0.00038, Acc: 98.95, Time: 33.3 s\n",
      "[6/20] Loss: 0.00029, Acc: 99.22, Time: 33.3 s\n",
      "[7/20] Loss: 0.00022, Acc: 99.45, Time: 33.2 s\n",
      "[8/20] Loss: 0.00018, Acc: 99.59, Time: 33.2 s\n",
      "[9/20] Loss: 0.00014, Acc: 99.68, Time: 33.5 s\n",
      "[10/20] Loss: 0.00011, Acc: 99.77, Time: 33.4 s\n",
      "[11/20] Loss: 0.00009, Acc: 99.84, Time: 33.4 s\n",
      "[12/20] Loss: 0.00007, Acc: 99.89, Time: 33.5 s\n",
      "[13/20] Loss: 0.00007, Acc: 99.89, Time: 33.4 s\n",
      "[14/20] Loss: 0.00005, Acc: 99.94, Time: 33.7 s\n",
      "[15/20] Loss: 0.00004, Acc: 99.95, Time: 33.5 s\n",
      "[16/20] Loss: 0.00004, Acc: 99.96, Time: 33.6 s\n",
      "[17/20] Loss: 0.00004, Acc: 99.96, Time: 33.6 s\n",
      "[18/20] Loss: 0.00003, Acc: 99.98, Time: 33.6 s\n",
      "[19/20] Loss: 0.00002, Acc: 99.98, Time: 34.8 s\n",
      "[20/20] Loss: 0.00002, Acc: 99.99, Time: 34.2 s\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "criterian = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(vgg_model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# device: GPU  or CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vgg_model.to(device)\n",
    "\n",
    "print(\"Start Training!\")\n",
    "\n",
    "num_epoches = 20\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    batch_size = 100\n",
    "    start = time.time()\n",
    "    \n",
    "    for (img, label) in trainloader:\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        outputs = vgg_model(img)\n",
    "        loss = criterian(outputs, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, pred = outputs.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        running_acc += num_correct\n",
    "    \n",
    "    running_loss /= len(trainset)\n",
    "    running_acc /= len(trainset)\n",
    "    print(\"[%d/%d] Loss: %.5f, Acc: %.2f, Time: %.1f s\" %(epoch+1, num_epoches, running_loss, 100*running_acc, time.time()-start))\n",
    "\n",
    "print(\"Finished Training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type VGG. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "torch.save(vgg_model, 'model/vgg11_MNIST.pkl')\n",
    "net = torch.load('model/vgg11_MNIST.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.00048, Acc: 98.62, Time: 2.6 s\n"
     ]
    }
   ],
   "source": [
    "# 评价\n",
    "testloss = 0.\n",
    "testacc = 0.\n",
    "start = time.time()\n",
    "for (img, label) in testloader:\n",
    "    img = img.to(device)\n",
    "    label = label.to(device)\n",
    "    \n",
    "    outputs = net(img)\n",
    "    loss = criterian(outputs, label)\n",
    "    \n",
    "    testloss += loss.item()\n",
    "    _, pred = outputs.max(1)\n",
    "    num_correct = (pred == label).sum().item()\n",
    "    testacc += num_correct\n",
    "    \n",
    "testloss /= len(testset)\n",
    "testacc /= len(testset)\n",
    "print(\"Test: Loss: %.5f, Acc: %.2f, Time: %.1f s\" %(testloss, 100*testacc, time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 相对于AlexNet  test_loss=97.09%   vgg11的test_loss=98.62%有了明显的提升  说明VGG还是更优秀些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2  在CIFAR 数据集上测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10\n",
    "cifar 10 这个数据集一共有 50000 张训练集，10000 张测试集，两个数据集里面的图片都是 png 彩色图片，图片大小是 32 x 32 x 3，一共是 10 分类问题，分别为飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。这个数据集是对网络性能测试一个非常重要的指标，可以说如果一个网络在这个数据集上超过另外一个网络，那么这个网络性能上一定要比另外一个网络好，目前这个数据集最好的结果是 **95%** 左右的测试集准确率。\n",
    "\n",
    "![](https://ws1.sinaimg.cn/large/006tNc79ly1fmpjxxq7wcj30db0ae7ag.jpg)\n",
    "\n",
    "你能用肉眼对这些图片进行分类吗？\n",
    "\n",
    "cifar 10 已经被 pytorch 内置了，使用非常方便，只需要调用 `torchvision.datasets.CIFAR10` 就可以了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace)\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (27): ReLU(inplace)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络结构\n",
    "\n",
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M',\n",
    "          512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512,\n",
    "          512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512,\n",
    "          512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    \n",
    "    def __init__(self, features, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "    \n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3   # CIFAR为彩色图像 通道数为 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def vgg11(**kwargs):\n",
    "    return VGG(make_layers(cfg['A'], batch_norm=True), **kwargs)\n",
    "\n",
    "\n",
    "def vgg13(**kwargs):\n",
    "    return VGG(make_layers(cfg['B'], batch_norm=True), **kwargs)\n",
    "\n",
    "\n",
    "def vgg16(**kwargs):\n",
    "    return VGG(make_layers(cfg['D'], batch_norm=True), **kwargs)\n",
    "\n",
    "\n",
    "def vgg19(**kwargs):\n",
    "    return VGG(make_layers(cfg['E'], batch_norm=True), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 数据增强\n",
    "# transform = transforms.Compose(\n",
    "# [\n",
    "#     transforms.RandomHorizontalFlip(),   # 对图片进行概率为0.5 随机翻转\n",
    "#     transforms.RandomGrayscale(),         # 随机调整图片的亮度\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "import numpy as np\n",
    "\n",
    "def data_tf(x):\n",
    "    x = np.array(x, dtype='float32') / 255\n",
    "    x = (x - 0.5) / 0.5    # 标准化，这个技巧常用到\n",
    "    x = x.transpose((2, 0, 1)) # transpose 为转置函数    将 channel 放到第一维，只是 pytorch 要求的输入方式\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# 加载数据\n",
    "trainset = torchvision.datasets.CIFAR10(root='data/', train=True, download=True, transform=data_tf)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='data/', train=False, download=True, transform=data_tf)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg_model = vgg11() \n",
    "vgg_model = vgg19()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(vgg_model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数  免得每次都得写一大坨\n",
    "def train(net, train_data, valid_data, num_epochs, optimizer, criterion):\n",
    "    \n",
    "    # device: GPU  or CPU\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    vgg_model.to(device)\n",
    "    print(\"Start...\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_loss = 0.\n",
    "        train_acc = 0.\n",
    "        start = time.time()       \n",
    "        for (img, label) in train_data:\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            outputs = vgg_model(img)\n",
    "            loss = criterion(outputs, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, pred = outputs.max(1)\n",
    "            num_correct = (pred == label).sum().item()\n",
    "            train_acc += num_correct\n",
    "\n",
    "        train_loss /= len(train_data)\n",
    "        train_acc /= len(train_data)\n",
    "        \n",
    "        \n",
    "        eval_loss = 0.\n",
    "        eval_acc = 0.\n",
    "        for (img, label) in valid_data:\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            outputs = vgg_model(img)\n",
    "            loss = criterion(outputs, label)\n",
    "            eval_loss += loss.item()\n",
    "            _, pred = outputs.max(1)\n",
    "            num_correct = (pred == label).sum().item()\n",
    "            eval_acc += num_correct\n",
    "            \n",
    "        eval_loss /= len(valid_data)\n",
    "        eval_acc /= len(valid_data)\n",
    "        print('epoch: {}, Train Loss: {:.6f}, Train Acc: {:.6f}, Eval Loss: {:.6f}, Eval Acc: {:.6f}, Time: {:.1f} s'\n",
    "          .format(epoch+1, train_loss, train_acc, eval_loss, eval_acc, time.time()-start))    \n",
    "       \n",
    "    print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start...\n",
      "epoch: 0, Train Loss: 1.825938, Train Acc: 22.932225, Eval Loss: 2.024197, Eval Acc: 31.394904, Time: 66.7 s\n",
      "epoch: 1, Train Loss: 0.981903, Train Acc: 41.923274, Eval Loss: 1.335038, Eval Acc: 36.159236, Time: 67.3 s\n",
      "epoch: 2, Train Loss: 0.691300, Train Acc: 48.723785, Eval Loss: 0.793959, Eval Acc: 46.363057, Time: 68.8 s\n",
      "epoch: 3, Train Loss: 0.521801, Train Acc: 52.501279, Eval Loss: 0.934406, Eval Acc: 44.993631, Time: 71.3 s\n",
      "epoch: 4, Train Loss: 0.401812, Train Acc: 55.028133, Eval Loss: 0.936934, Eval Acc: 46.210191, Time: 71.2 s\n",
      "epoch: 5, Train Loss: 0.312005, Train Acc: 57.101023, Eval Loss: 2.135915, Eval Acc: 42.923567, Time: 70.7 s\n",
      "epoch: 6, Train Loss: 0.251198, Train Acc: 58.432225, Eval Loss: 0.723369, Eval Acc: 50.433121, Time: 69.5 s\n",
      "epoch: 7, Train Loss: 0.184134, Train Acc: 59.881074, Eval Loss: 0.807630, Eval Acc: 48.834395, Time: 68.2 s\n",
      "epoch: 8, Train Loss: 0.145900, Train Acc: 60.760870, Eval Loss: 0.837917, Eval Acc: 50.044586, Time: 68.3 s\n",
      "epoch: 9, Train Loss: 0.111845, Train Acc: 61.447570, Eval Loss: 0.695195, Eval Acc: 52.254777, Time: 68.1 s\n",
      "epoch: 10, Train Loss: 0.088421, Train Acc: 62.005115, Eval Loss: 0.766990, Eval Acc: 52.140127, Time: 68.1 s\n",
      "epoch: 11, Train Loss: 0.075490, Train Acc: 62.294118, Eval Loss: 0.748182, Eval Acc: 52.420382, Time: 68.2 s\n",
      "epoch: 12, Train Loss: 0.061361, Train Acc: 62.606138, Eval Loss: 0.748558, Eval Acc: 52.656051, Time: 68.0 s\n",
      "epoch: 13, Train Loss: 0.054000, Train Acc: 62.727621, Eval Loss: 0.911824, Eval Acc: 51.732484, Time: 68.0 s\n",
      "epoch: 14, Train Loss: 0.045176, Train Acc: 62.913043, Eval Loss: 0.796180, Eval Acc: 53.006369, Time: 68.1 s\n",
      "epoch: 15, Train Loss: 0.040621, Train Acc: 63.053708, Eval Loss: 0.794456, Eval Acc: 52.923567, Time: 68.0 s\n",
      "epoch: 16, Train Loss: 0.034027, Train Acc: 63.212276, Eval Loss: 0.814756, Eval Acc: 52.961783, Time: 68.1 s\n",
      "epoch: 17, Train Loss: 0.030058, Train Acc: 63.304348, Eval Loss: 0.835195, Eval Acc: 52.866242, Time: 68.1 s\n",
      "epoch: 18, Train Loss: 0.024149, Train Acc: 63.429668, Eval Loss: 0.867335, Eval Acc: 52.757962, Time: 68.6 s\n",
      "epoch: 19, Train Loss: 0.025375, Train Acc: 63.390026, Eval Loss: 0.875148, Eval Acc: 52.509554, Time: 68.4 s\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# 训练网络\n",
    "train(vgg_model, trainloader, testloader, 20, optimizer, criterion)   # num_epoches = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG11 训练20轮的效果大概为 Train Loss: 0.020202, Train Acc: 63.524297, Eval Loss: 1.317068, Eval Acc: 49.878981, Time: 35.7 s\n",
    "<br>\n",
    "VGG19 训练20轮的效果大概为 Train Loss: 0.025375, Train Acc: 63.390026, Eval Loss: 0.875148, Eval Acc: 52.509554, Time: 68.4 s\n",
    "\n",
    "<br>\n",
    "效果都不咋好  需要重构网络 或者调参试试。。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type VGG. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "torch.save(vgg_model, 'model/VGG19_CAFIR.pkl')\n",
    "net = torch.load('model/VGG19_CAFIR.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
