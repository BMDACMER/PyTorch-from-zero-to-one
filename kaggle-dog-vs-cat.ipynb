{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 采用预训练方式 进行训练\n",
    "\n",
    "## 1 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "\n",
    "import os    # 用来加载数据\n",
    "import shutil     # 用来移动图片\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**将下载好的文件放到对应的目录**\n",
    "\n",
    "train.zip  里面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 猫狗文件夹 (注意运行一次就行)\n",
    "train_root = './kaggle/train/'\n",
    "dog_folder = os.path.join(train_root, 'dog')\n",
    "cat_folder = os.path.join(train_root, 'cat')\n",
    "os.mkdir(dog_folder)\n",
    "os.mkdir(cat_folder)\n",
    "\n",
    "val_root = './kaggle/val'\n",
    "dog_folder = os.path.join(val_root, 'dog')\n",
    "cat_folder = os.path.join(val_root, 'cat')\n",
    "os.mkdir(dog_folder)\n",
    "os.mkdir(cat_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将猫和狗的图片分别移到对应的文件夹里\n",
    "data_file = os.listdir('./data/zip/')\n",
    "\n",
    "dog_file = list(filter(lambda x:x[:3]=='dog', data_file))  # filter(function, iterable)\n",
    "cat_file = list(filter(lambda x:x[:3]=='cat', data_file))\n",
    "\n",
    "root = './data/'\n",
    "# 移动狗的图片\n",
    "for i in range(len(dog_file)):\n",
    "    pic_path = root + 'zip/' + dog_file[i]\n",
    "    if i < len(dog_file)*0.9:\n",
    "        obj_path = train_root + '/dog/' + dog_file[i]\n",
    "    else:\n",
    "        obj_path = val_root + '/dog/' + dog_file[i]\n",
    "    shutil.move(pic_path, obj_path)     # 移动图片\n",
    "# 移动猫的图片    \n",
    "for i in range(len(cat_file)):\n",
    "    pic_path = root + 'zip/' + cat_file[i]\n",
    "    if i < len(cat_file)*0.9:\n",
    "        obj_path = train_root + '/cat/' + cat_file[i]\n",
    "    else:\n",
    "        obj_path = val_root + '/cat/' + cat_file[i]\n",
    "    shutil.move(pic_path, obj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogfiles = os.listdir('kaggle/train/dog/')\n",
    "catfiles = os.listdir('kaggle/train/cat/')\n",
    "\n",
    "dogfile = list(filter(lambda x:x[:3]=='dog', dogfiles))\n",
    "catfile = list(filter(lambda x:x[:3]=='cat', catfiles))\n",
    "\n",
    "# 从拆分的数据集中随机取一张图片\n",
    "dog_show = np.random.choice(dogfile, size=1)      # (dataset, size, replace, p)  size表示抽取多少个\n",
    "cat_show = np.random.choice(catfile, size=1)\n",
    "\n",
    "dog_path_show = plt.imread('kaggle/train/dog/' + dog_show[0])  # 注意 不能为 dog_show  得为 dog_show[0]\n",
    "cat_path_show = plt.imread('kaggle/train/cat/' + cat_show[0])  # 注意不能为 cat_show  得为 cat_show[0]\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(dog_path_show)\n",
    "ax2.imshow(cat_path_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 采用预训练方式\n",
    "\n",
    "- resnet18  (通过设置fix_param 来控制是否需要进行卷积层参数的更新)\n",
    "- vgg19,inceptionv3,resnet152组合的预训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch import optim, nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据增强\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(299),  # transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2)\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))        \n",
    "    ]),\n",
    "    'val':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(320),    # 将原来的Scale 替换为Resize\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10\n",
      "******************** train ********************\n",
      "Loss: 0.402148, Acc: 0.8263\n",
      "Loss: 0.322686, Acc: 0.8667\n",
      "Loss: 0.285819, Acc: 0.8834\n",
      "Loss: 0.267471, Acc: 0.8896\n",
      "Loss: 0.251834, Acc: 0.8948\n",
      "Loss: 0.240083, Acc: 0.8997\n",
      "Loss: 0.236034, Acc: 0.9008\n",
      "Loss: 0.235792, Acc: 0.9008, Time: 378s\n",
      "Validation\n",
      "Loss: 0.067775   Acc:0.9752\n",
      "2/10\n",
      "******************** train ********************\n",
      "Loss: 0.183648, Acc: 0.9222\n",
      "Loss: 0.186092, Acc: 0.9189\n",
      "Loss: 0.183786, Acc: 0.9196\n",
      "Loss: 0.195190, Acc: 0.9134\n",
      "Loss: 0.192634, Acc: 0.9147\n",
      "Loss: 0.190080, Acc: 0.9158\n",
      "Loss: 0.190055, Acc: 0.9148\n",
      "Loss: 0.189941, Acc: 0.9149, Time: 90s\n",
      "Validation\n",
      "Loss: 0.061061   Acc:0.9764\n",
      "3/10\n",
      "******************** train ********************\n",
      "Loss: 0.169788, Acc: 0.9206\n",
      "Loss: 0.172517, Acc: 0.9225\n",
      "Loss: 0.178542, Acc: 0.9205\n",
      "Loss: 0.177521, Acc: 0.9208\n",
      "Loss: 0.175774, Acc: 0.9213\n",
      "Loss: 0.177689, Acc: 0.9214\n",
      "Loss: 0.176160, Acc: 0.9221\n",
      "Loss: 0.175990, Acc: 0.9223, Time: 91s\n",
      "Validation\n",
      "Loss: 0.068427   Acc:0.9728\n",
      "4/10\n",
      "******************** train ********************\n",
      "Loss: 0.178309, Acc: 0.9187\n",
      "Loss: 0.183417, Acc: 0.9198\n",
      "Loss: 0.193161, Acc: 0.9161\n",
      "Loss: 0.190341, Acc: 0.9170\n",
      "Loss: 0.198922, Acc: 0.9137\n",
      "Loss: 0.192627, Acc: 0.9168\n",
      "Loss: 0.192585, Acc: 0.9165\n",
      "Loss: 0.192801, Acc: 0.9165, Time: 94s\n",
      "Validation\n",
      "Loss: 0.053649   Acc:0.9804\n",
      "5/10\n",
      "******************** train ********************\n",
      "Loss: 0.166504, Acc: 0.9269\n",
      "Loss: 0.172067, Acc: 0.9252\n",
      "Loss: 0.170501, Acc: 0.9258\n",
      "Loss: 0.170485, Acc: 0.9257\n",
      "Loss: 0.172797, Acc: 0.9242\n",
      "Loss: 0.175819, Acc: 0.9229\n",
      "Loss: 0.178055, Acc: 0.9217\n",
      "Loss: 0.177918, Acc: 0.9216, Time: 94s\n",
      "Validation\n",
      "Loss: 0.069922   Acc:0.9712\n",
      "6/10\n",
      "******************** train ********************\n",
      "Loss: 0.174894, Acc: 0.9191\n",
      "Loss: 0.167276, Acc: 0.9242\n",
      "Loss: 0.173212, Acc: 0.9239\n",
      "Loss: 0.177350, Acc: 0.9227\n",
      "Loss: 0.173599, Acc: 0.9243\n",
      "Loss: 0.174047, Acc: 0.9243\n",
      "Loss: 0.174205, Acc: 0.9251\n",
      "Loss: 0.173854, Acc: 0.9253, Time: 94s\n",
      "Validation\n",
      "Loss: 0.055020   Acc:0.9792\n",
      "7/10\n",
      "******************** train ********************\n",
      "Loss: 0.182943, Acc: 0.9231\n",
      "Loss: 0.189451, Acc: 0.9187\n",
      "Loss: 0.188770, Acc: 0.9177\n",
      "Loss: 0.184388, Acc: 0.9189\n",
      "Loss: 0.184513, Acc: 0.9190\n",
      "Loss: 0.185661, Acc: 0.9176\n",
      "Loss: 0.184660, Acc: 0.9187\n",
      "Loss: 0.185176, Acc: 0.9186, Time: 98s\n",
      "Validation\n",
      "Loss: 0.059593   Acc:0.9760\n",
      "8/10\n",
      "******************** train ********************\n",
      "Loss: 0.234793, Acc: 0.9038\n",
      "Loss: 0.207868, Acc: 0.9128\n",
      "Loss: 0.193929, Acc: 0.9182\n",
      "Loss: 0.187373, Acc: 0.9221\n",
      "Loss: 0.186815, Acc: 0.9223\n",
      "Loss: 0.181917, Acc: 0.9238\n",
      "Loss: 0.180649, Acc: 0.9241\n",
      "Loss: 0.180412, Acc: 0.9241, Time: 100s\n",
      "Validation\n",
      "Loss: 0.057831   Acc:0.9752\n",
      "9/10\n",
      "******************** train ********************\n",
      "Loss: 0.155066, Acc: 0.9278\n",
      "Loss: 0.170970, Acc: 0.9239\n",
      "Loss: 0.172684, Acc: 0.9244\n",
      "Loss: 0.168480, Acc: 0.9260\n",
      "Loss: 0.169966, Acc: 0.9254\n",
      "Loss: 0.168611, Acc: 0.9253\n",
      "Loss: 0.171289, Acc: 0.9252\n",
      "Loss: 0.171359, Acc: 0.9252, Time: 97s\n",
      "Validation\n",
      "Loss: 0.053349   Acc:0.9796\n",
      "10/10\n",
      "******************** train ********************\n",
      "Loss: 0.181142, Acc: 0.9206\n",
      "Loss: 0.182495, Acc: 0.9208\n",
      "Loss: 0.186470, Acc: 0.9185\n",
      "Loss: 0.186749, Acc: 0.9177\n",
      "Loss: 0.184101, Acc: 0.9185\n",
      "Loss: 0.179908, Acc: 0.9206\n",
      "Loss: 0.183274, Acc: 0.9199\n",
      "Loss: 0.183154, Acc: 0.9199, Time: 102s\n",
      "Validation\n",
      "Loss: 0.050918   Acc:0.9784\n",
      "Finish Training!\n"
     ]
    }
   ],
   "source": [
    "# 使用ImageFolder定义数据文件夹以从文件夹中获取图像和类\n",
    "root = 'kaggle/'\n",
    "data_folder = {\n",
    "    'train':\n",
    "    ImageFolder(\n",
    "        os.path.join(root, 'train'), transform=data_transforms['train']),\n",
    "    'val':\n",
    "    ImageFolder(\n",
    "        os.path.join(root, 'val'), transform=data_transforms['val'])\n",
    "}\n",
    "\n",
    "# 定义dataloader  加载数据\n",
    "batch_size = 32\n",
    "dataloader = {\n",
    "    'train':\n",
    "    DataLoader(\n",
    "        data_folder['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4),\n",
    "    'val':\n",
    "    DataLoader(\n",
    "        data_folder['val'],\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4)\n",
    "}\n",
    "\n",
    "# 获取训练集集和验证集的大小\n",
    "data_size = {\n",
    "    'train': len(dataloader['train'].dataset),\n",
    "    'val': len(dataloader['val'].dataset)\n",
    "}\n",
    "\n",
    "# 获取类别数\n",
    "img_classes = len(dataloader['train'].dataset.classes)\n",
    "\n",
    "#device : GPU or CPU\n",
    "use_gpu = torch.cuda.is_available()   #  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "fix_param = True    # 是否固定卷积层参数\n",
    "\n",
    "# 定义model\n",
    "transfer_model = models.resnet18(pretrained=True)\n",
    "\n",
    "\n",
    "if fix_param:\n",
    "    for param in transfer_model.parameters():\n",
    "        param.requires_grad = False\n",
    "dim_in = transfer_model.fc.in_features\n",
    "transfer_model.fc = nn.Linear(dim_in, img_classes)    # 此时这里img_classes=2为猫和狗两类\n",
    "\n",
    "if use_gpu:\n",
    "    transfer_model = transfer_model.cuda()\n",
    "\n",
    "# 如果固定卷积层参数，只需要更新全连接层参数即可， 否则需要全部更新\n",
    "if fix_param:\n",
    "    optimizer = optim.Adam(transfer_model.fc.parameters(), lr=1e-3)\n",
    "else:\n",
    "    optimizer = optim.Adam(transfer_model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# train\n",
    "num_epoch = 10\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    print('{}/{}'.format(epoch+1, num_epoch))\n",
    "    print('*'*20+' train ' + '*'*20)\n",
    "    transfer_model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    since = time.time()\n",
    "    \n",
    "    for i, data in enumerate(dataloader['train'], 1):\n",
    "        img, label = data\n",
    "        if use_gpu:\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "\n",
    "        # forward\n",
    "        out = transfer_model(img)\n",
    "        loss = criterion(out, label)\n",
    "        _, pred = torch.max(out, 1)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * label.size(0)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        running_acc += num_correct\n",
    "        if i % 100 == 0:\n",
    "            print('Loss: {:.6f}, Acc: {:.4f}'.format(running_loss / (\n",
    "                i * batch_size), running_acc / (i * batch_size)))\n",
    "            \n",
    "    running_loss /= data_size['train']\n",
    "    running_acc /= data_size['train']\n",
    "    elips_time = time.time() - since\n",
    "    print('Loss: {:.6f}, Acc: {:.4f}, Time: {:.0f}s'.format(\n",
    "        running_loss, running_acc, elips_time))\n",
    "    \n",
    "    print('Validation')\n",
    "    transfer_model.eval()\n",
    "    num_correct=0.0\n",
    "    total = 0.0\n",
    "    eval_loss = 0.0\n",
    "    for data in dataloader['val']:\n",
    "        img, label = data\n",
    "        img = Variable(img).cuda()\n",
    "        label = Variable(label).cuda()\n",
    "        out = transfer_model(img)\n",
    "        _, pred = out.max(1)\n",
    "        loss = criterion(out, label)\n",
    "        eval_loss += loss.item() * label.size(0)\n",
    "        num_correct += (pred == label).sum().item()\n",
    "        total += label.size(0)\n",
    "        \n",
    "    print('Loss: {:.6f}   Acc:{:.4f}'.format(eval_loss/total, num_correct/total))\n",
    "    \n",
    "print('Finish Training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用迁移学习，组合多个预训练网络，都将它们的卷积层参数固定，只更新最后的全连接层的参数，在每一次迭代中，都需要将图片前向传播，通过卷积层到全连接层，最后输出结果，接着进行反向传播更新全连接层的参数。如果数据集特别大，这样做效率特别低，因为卷积层的参数没有更新，所以每次迭代中数据集前向传播经过卷积层的结果是一样的，所以每次迭代中数据集前向传播经过卷积层的结果是一样的，所以没有必要每次都进行前向传播，只需要将数据集一次迭代中前向传播经过卷积网络的结果保存起来就可以了，这个结果成为特征向量**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多个预训练网络 不好在jupyter里炒作，写成.py文件在pycharm中运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
