{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic回归的代码实现\n",
    "\n",
    "- 参考课本P45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定随机种子\n",
    "torch.manual_seed(2019)\n",
    "\n",
    "# 从data.txt读入数据，读入数据点之后，根据不同的label将数据点分为红色和蓝色，并且画图展示出来了\n",
    "with open('data/data.txt', 'r') as f:\n",
    "    data_list = f.readlines()\n",
    "    data_list = [i.split('\\n')[0] for i in data_list]   # 去除每行最后一换行符\n",
    "    data_list = [i.split(',') for i in data_list]   # 去除逗号\n",
    "    data = [(float(i[0]), float(i[1]), float(i[2])) for i in data_list]    # 取出三个数据   这里是（100，3）\n",
    "    \n",
    "# 标准化   x0-----(n,3)    x1 ----(m, 3)\n",
    "x0 = list(filter(lambda x:x[-1] == 0.0, data))  # lambda argument_list: expression ，  filter(function, iterable)参考https://www.runoob.com/python/python-func-filter.html\n",
    "x1 = list(filter(lambda x:x[-1] == 1.0, data))\n",
    "plot_x0_0 = [i[0] for i in x0]   # 横坐标\n",
    "plot_x0_1 = [i[1] for i in x0]   # 纵坐标\n",
    "plot_x1_0 = [i[0] for i in x1]   # 横坐标\n",
    "plot_x1_1 = [i[1] for i in x1]   # 纵坐标\n",
    "\n",
    "plt.plot(plot_x0_0, plot_x0_1, 'ro', label='x_0')\n",
    "plt.plot(plot_x1_0, plot_x1_1, 'bo', label='x_1')\n",
    "plt.legend(loc='best')   # loc='best'最佳展示位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**接下来将数据转成numpy类型，接着转到Tensor为之后的训练作准备**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = np.array(data, dtype='float32')   # 转换为numpy array\n",
    "x_data = torch.from_numpy(np_data[:, 0:2])    # 转换成Tensor，大小是[100, 2]\n",
    "y_data = torch.from_numpy(np_data[:, -1]).view(-1,1)  # 转换成Tensor，大小是[100,1]\n",
    "print('y_data:',y_data.shape)\n",
    "\n",
    "# 定义 sigmoid 函数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# 画出 sigmoid 的图像\n",
    "plot_x = np.arange(-10, 10.01, 0.01)\n",
    "plot_y = sigmoid(plot_x)\n",
    "\n",
    "plt.plot(plot_x, plot_y, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取tensor 中数据\n",
    "x_data = Variable(x_data)   # (100,2)\n",
    "y_train = Variable(y_data)   # (100, 1)\n",
    "\n",
    "import torch.nn.functional as F   # 后续需要用到函数，不用自己写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 logistic 回归模型\n",
    "w = Variable(torch.randn(2, 1), requires_grad=True) \n",
    "b = Variable(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "def logistic_regression(x):\n",
    "    return F.sigmoid(torch.mm(x, w) + b)\n",
    "\n",
    "# 画出参数更新之前的结果\n",
    "w0 = w[0].data[0].numpy()\n",
    "w1 = w[1].data[0].numpy()\n",
    "b0 = b.data[0].numpy()\n",
    "\n",
    "plot_x = np.arange(0.2, 1, 0.01)\n",
    "plot_y = (-w0 * plot_x - b0) / w1\n",
    "\n",
    "plt.plot(plot_x, plot_y, 'g', label='cutting line')\n",
    "plt.plot(plot_x0_0, plot_x0_1, 'ro', label='x_0')\n",
    "plt.plot(plot_x1_0, plot_x1_1, 'bo', label='x_1')\n",
    "plt.legend(loc='best')   # loc='best'最佳展示位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算loss\n",
    "def binary_loss(y_pred, y):\n",
    "    logits = (y * y_pred.clamp(1e-12).log() + (1 - y) * (1 - y_pred).clamp(1e-12).log()).mean()\n",
    "    return -logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_regression(x_data)\n",
    "loss = binary_loss(y_pred, y_data)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 torch.optim 更新参数\n",
    "from torch import nn\n",
    "w = nn.Parameter(torch.randn(2, 1))\n",
    "b = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "def logistic_regression(x):\n",
    "    return F.sigmoid(torch.mm(x, w) + b)\n",
    "\n",
    "optimizer = torch.optim.SGD([w, b], lr=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行 1000 次更新\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "for e in range(1000):\n",
    "    # 前向传播\n",
    "    y_pred = logistic_regression(x_data)\n",
    "    loss = binary_loss(y_pred, y_data) # 计算 loss\n",
    "    # 反向传播\n",
    "    optimizer.zero_grad() # 使用优化器将梯度归 0\n",
    "    loss.backward()\n",
    "    optimizer.step() # 使用优化器来更新参数\n",
    "    # 计算正确率\n",
    "    mask = y_pred.ge(0.5).float()  # 大于0.5等于1，小于0.5等于0\n",
    "    acc = (mask == y_data).sum().item() / y_data.shape[0]\n",
    "    if (e + 1) % 200 == 0:\n",
    "        print('epoch: {}, Loss: {:.5f}, Acc: {:.5f}'.format(e+1, loss.item(), acc))\n",
    "during = time.time() - start\n",
    "print()\n",
    "print('During Time: {:.3f} s'.format(during))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出更新之后的结果\n",
    "w0 = w[0].data[0].numpy()\n",
    "w1 = w[1].data[0].numpy()\n",
    "b0 = b.data[0].numpy()\n",
    "\n",
    "plot_x = np.arange(0.2, 1, 0.01)\n",
    "plot_y = (-w0 * plot_x - b0) / w1\n",
    "\n",
    "plt.plot(plot_x, plot_y, 'g', label='cutting line')\n",
    "plt.plot(plot_x0_0, plot_x0_1, 'ro', label='x_0')\n",
    "plt.plot(plot_x1_0, plot_x1_1, 'bo', label='x_1')\n",
    "plt.legend(loc='best')   # loc='best'最佳展示位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用自带的loss\n",
    "criterion = nn.BCEWithLogitsLoss() # 将 sigmoid 和 loss 写在一层，有更快的速度、更好的稳定性\n",
    "\n",
    "w = nn.Parameter(torch.randn(2, 1))\n",
    "b = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "def logistic_reg(x):\n",
    "    return torch.mm(x, w) + b\n",
    "\n",
    "optimizer = torch.optim.SGD([w, b], 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_reg(x_data)\n",
    "loss = criterion(y_pred, y_data)\n",
    "print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同样进行 1000 次更新\n",
    "\n",
    "start = time.time()\n",
    "for e in range(1000):\n",
    "    # 前向传播\n",
    "    y_pred = logistic_reg(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    # 反向传播\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 计算正确率\n",
    "    mask = y_pred.ge(0.5).float()\n",
    "    acc = (mask == y_data).sum().item() / y_data.shape[0]\n",
    "    if (e + 1) % 200 == 0:\n",
    "        print('epoch: {}, Loss: {:.5f}, Acc: {:.5f}'.format(e+1, loss.item(), acc))\n",
    "\n",
    "during = time.time() - start\n",
    "print()\n",
    "print('During Time: {:.3f} s'.format(during))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 整理上诉代码  如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.lr = nn.Linear(2, 1)\n",
    "        self.sm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lr(x)\n",
    "        x = self.sm(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "def file_open():\n",
    "    with open('data/data.txt', 'r') as f:\n",
    "        data_list = f.readlines()\n",
    "        data_list = [i.split('\\n')[0] for i in data_list]\n",
    "        data_list = [i.split(',') for i in data_list]\n",
    "        data = [(float(i[0]), float(i[1]), float(i[2])) for i in data_list]\n",
    "        data = torch.Tensor(data)\n",
    "        \n",
    "        return data\n",
    "\n",
    "def train(n_epoch, data):\n",
    "    for epoch in range(n_epoch):\n",
    "        if torch.cuda.is_available():\n",
    "            x = Variable(data[:, 0:2]).cuda()\n",
    "            y = Variable(data[:, 2]).cuda().view(-1,1)\n",
    "        else:\n",
    "            x = Variable(data[:, 0:2])\n",
    "            y = Variable(data[:, -1]).view(-1,1)\n",
    "\n",
    "        # forward\n",
    "        out = logistic_model(x)\n",
    "        loss = criterion(out, y)\n",
    "        print_loss = loss.data.item()\n",
    "        mask = out.ge(0.5).float()\n",
    "        correct = (mask == y).sum()\n",
    "        acc = correct.item() / x.size(0)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 1000 == 0:\n",
    "            print(\"epoch{} ----- loss:{}-------acc:{}\".format(epoch+1, loss, acc))\n",
    "\n",
    "def plot(logistic_model):\n",
    "    # 预测的函数模型，将数据点分开\n",
    "    w0, w1 = logistic_model.lr.weight[0]\n",
    "    w0 = w0.item()\n",
    "    w1 = w1.item()\n",
    "    b = logistic_model.lr.bias.item()\n",
    "    plot_x = np.arange(30, 100, 0.1)\n",
    "    plot_y = (-w0 * plot_x - b) / w1\n",
    "    plt.plot(plot_x, plot_y)\n",
    "    \n",
    "    # 将数据点画出来\n",
    "    x0 = list(filter(lambda x: x[-1] == 0.0, data))\n",
    "    x1 = list(filter(lambda x: x[-1] == 1.0, data))\n",
    "    plot_x0_0 = [i[0] for i in x0]\n",
    "    plot_x0_1 = [i[1] for i in x0]\n",
    "    plot_x1_0 = [i[0] for i in x1]\n",
    "    plot_x1_1 = [i[1] for i in x1]\n",
    "\n",
    "    plt.plot(plot_x0_0, plot_x0_1, 'ro', label='x_0')\n",
    "    plt.plot(plot_x1_0, plot_x1_1, 'bo', label='x_1')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # 读取数据\n",
    "    data = file_open()\n",
    "    print(\"data shape\",data.shape)\n",
    "    # 加载模型\n",
    "    logistic_model = LogisticRegression()\n",
    "    if torch.cuda.is_available():\n",
    "        logistic_model.cuda()\n",
    "    \n",
    "    #定义评价标准 和 优化器\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(logistic_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "    \n",
    "    # 开始训练\n",
    "    n_epoch = 3000\n",
    "    train(n_epoch, data)\n",
    "    \n",
    "    # 画出图像\n",
    "    plot(logistic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Logistic 回归的代码实现\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.lr = nn.Linear(2, 1)\n",
    "        self.sm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lr(x)\n",
    "        x = self.sm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with open('data/data.txt', 'r', encoding='utf8') as f:\n",
    "        data_list = f.readlines()\n",
    "        data_list = [i.split('\\n')[0] for i in data_list]\n",
    "        data_list = [i.split(',') for i in data_list]\n",
    "        data = [(float(i[0]), float(i[1]), float(i[2])) for i in data_list]\n",
    "        data = torch.Tensor(data)\n",
    "\n",
    "    logistic_model = LogisticRegression()\n",
    "    if torch.cuda.is_available():\n",
    "        logistic_model.cuda()\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(logistic_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "    for epoch in range(10000):\n",
    "        if torch.cuda.is_available():\n",
    "            x = Variable(data[:, 0:2]).cuda()\n",
    "            y = Variable(data[:, 2]).cuda().unsqueeze(1)\n",
    "        else:\n",
    "            x = Variable(data[:, 0:2])\n",
    "            y = Variable(data[:, 2]).unsqueeze(1)\n",
    "        # forward\n",
    "        out = logistic_model(x)\n",
    "        loss = criterion(out, y)\n",
    "        print_loss = loss.data.item()\n",
    "        mask = out.ge(0.5).float()\n",
    "        correct = (mask == y).sum()\n",
    "        acc = correct.item() / x.size(0)\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 1000 == 0:\n",
    "            print('*' * 10)\n",
    "            print(\"epoch{} ----- loss:{}-------acc:{}\".format(epoch+1, loss, acc))\n",
    "\n",
    "\n",
    "    w0, w1 = logistic_model.lr.weight[0]\n",
    "    w0 = w0.item()\n",
    "    w1 = w1.item()\n",
    "    b = logistic_model.lr.bias.item()\n",
    "    plot_x = np.arange(30, 100, 0.1)\n",
    "    plot_y = (-w0 * plot_x - b) / w1\n",
    "    plt.plot(plot_x, plot_y)\n",
    "\n",
    "    x0 = list(filter(lambda x: x[-1] == 0.0, data))\n",
    "    x1 = list(filter(lambda x: x[-1] == 1.0, data))\n",
    "    plot_x0_0 = [i[0] for i in x0]\n",
    "    plot_x0_1 = [i[1] for i in x0]\n",
    "    plot_x1_0 = [i[0] for i in x1]\n",
    "    plot_x1_1 = [i[1] for i in x1]\n",
    "\n",
    "    plt.plot(plot_x0_0, plot_x0_1, 'ro', label='x_0')\n",
    "    plt.plot(plot_x1_0, plot_x1_1, 'bo', label='x_1')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
